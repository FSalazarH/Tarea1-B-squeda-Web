{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "\n",
    "\n",
    "<center>\n",
    "    <h1> INF335 - Tecnologías de Búsqueda Web   </h1>\n",
    "    <h2> Tarea 1 </h2>\n",
    "    <h3> Universidad Técnica Federico Santa Maria </h3>\n",
    "    \n",
    "</center>\n",
    "\n",
    "_Marzo 2017_\n",
    "<p>Profesor: Marcelo Mendoza</p>\n",
    " <p>Ayudante: Daniel Rivera</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Objetivos </h2>\n",
    "<ul>\n",
    "<li  style =\"margin: 12px 0px; font-size:16px\"> Implementar y analizar la herramienta de python NLTK (Natural Language Tookit) para trabajar con procesamiento de texto y lenguaje natural. </li>\n",
    "<li style =\"margin: 12px 0px;font-size:16px \" > Estudiar e implementar las estructuras de datos adecuadas para representar un corpus, documentos y palabras con su categorización correspondiente.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h2>Dataset : Amazon Fine Food Review</h2>\n",
    "\n",
    "<p style=\"font-size:16px\"> Para esta tarea se va a trabajar con el dataset de <i>“Amazon Fine Food Review”</i> el cual contiene más de 500.000 críticas de platos de comida y restaurants provenientes de Amazon. El archivo consiste en un .csv (“Comma Separate Values”) el cual contiene la siguiente estructura:</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "<ol>\n",
    "<li style =\"margin: 5px 0px;\"> <strong>Id</strong> - Id único de cada reseña</li>\n",
    "<li style =\"margin: 8px 0px;\"><strong> ProductId</strong> - Id único que identifica el producto a analizar</li>\n",
    "<li style =\"margin: 8px 0px;\"><strong>UserId</strong> - Id único que identifica al usuario</li>\n",
    "<li style =\"margin: 8px 0px;\" ><strong>ProfileName</strong> - Nombre del usuario que realizó la reseña</li>\n",
    "<li style =\"margin: 8px 0px;\"><strong>HelpfulnessNumerator</strong> -  número de usuarios que indicaron que encontraron esta crítica util</li>\n",
    "<li style =\"margin: 8px 0px;\" ><strong>HelpfulnessDenominator</strong> número de usuarios que indicaron que encontraron esta crítica util -</li>\n",
    "<li style =\"margin: 8px 0px;\" ><strong>Score</strong> - Rating, con valores entre 1 y 5 estrellas</li>\n",
    "<li style =\"margin: 8px 0px;\" ><strong>Time</strong> - timestamp for the review</li>\n",
    "<li style =\"margin: 8px 0px;\" ><strong>Summary</strong> - breve resumen de la reseña</li>\n",
    "<li style =\"margin: 8px 0px;\"><strong>Text</strong> - string que contiene la reseña </li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:16px\" > <strong> Link Descarga Dataset: https://drive.google.com/open?id=0B1GNvIDVzwwLR2dwQVliRnBWMnM </strong>  </p> \n",
    "\n",
    "<p style=\"font-size:16px\" > <b> Objetivo: </b> Extraiga del documento el item “Text” y generé un corpus , almacenando en un string todas las reseñas del dataset . Usará esta variable para realizar las siguientes etapas de preprocesamiento de texto.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('amazon-fine-foods/Reviews.csv', encoding=\"utf8\") as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    reseña = []\n",
    "    for row in reader:\n",
    "        reseña.append(row['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#reseña[524000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Preprocesamiento:</h2>\n",
    "\n",
    "<ol >\n",
    "<li style =\"margin: 12px 0px;\" >\n",
    "<p style=\"font-size:16px\" > Si observa el corpus, se dará cuenta de que hay etiquetas <i>html</i> embebidas en algunas reseñas. Para eliminar estas etiquetas , use la libreria <i>Beautiful Soup</i> (link: https://www.crummy.com/software/BeautifulSoup/bs4/doc/).</p> </li>\n",
    "\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "reseñas = []\n",
    "for i in range(len(reseña)):\n",
    "    markup = reseña[i]\n",
    "    soup = BeautifulSoup(markup, 'lxml')\n",
    "    reseña_sintag = soup.get_text()\n",
    "    reseñas.append(reseña_sintag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labrador is finicky and she appreciates this product better than  most.',\n",
       " 'Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted. Not sure if this was an error or if the vendor intended to represent the product as \"Jumbo\".',\n",
       " 'This is a confection that has been around a few centuries.  It is a light, pillowy citrus gelatin with nuts - in this case Filberts. And it is cut into tiny squares and then liberally coated with powdered sugar.  And it is a tiny mouthful of heaven.  Not too chewy, and very flavorful.  I highly recommend this yummy treat.  If you are familiar with the story of C.S. Lewis\\' \"The Lion, The Witch, and The Wardrobe\" - this is the treat that seduces Edmund into selling out his Brother and Sisters to the Witch.',\n",
       " 'If you are looking for the secret ingredient in Robitussin I believe I have found it.  I got this in addition to the Root Beer Extract I ordered (which was good) and made some cherry soda.  The flavor is very medicinal.',\n",
       " 'Great taffy at a great price.  There was a wide assortment of yummy taffy.  Delivery was very quick.  If your a taffy lover, this is a deal.',\n",
       " 'I got a wild hair for taffy and ordered this five pound bag. The taffy was all very enjoyable with many flavors: watermelon, root beer, melon, peppermint, grape, etc. My only complaint is there was a bit too much red/black licorice-flavored pieces (just not my particular favorites). Between me, my kids, and my husband, this lasted only two weeks! I would recommend this brand of taffy -- it was a delightful treat.',\n",
       " \"This saltwater taffy had great flavors and was very soft and chewy.  Each candy was individually wrapped well.  None of the candies were stuck together, which did happen in the expensive version, Fralinger's.  Would highly recommend this candy!  I served it at a beach-themed party and everyone loved it!\",\n",
       " 'This taffy is so good.  It is very soft and chewy.  The flavors are amazing.  I would definitely recommend you buying it.  Very satisfying!!',\n",
       " \"Right now I'm mostly just sprouting this so my cats can eat the grass. They love it. I rotate it around with Wheatgrass and Rye too\",\n",
       " 'This is a very healthy dog food. Good for their digestion. Also good for small puppies. My dog eats her required amount at every feeding.']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reseñas is a list of reseñas of large 568454\n",
    "reseñas[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> A continuación, guardaremos el estado del corpus utilizando la librería Pickle </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Using Pickle for save de state of corpus\n",
    "import pickle\n",
    "\n",
    "pickle_out = open(\"list.pickle\", \"wb\")\n",
    "pickle.dump(reseñas, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correr desde acá"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle_in = open(\"list.pickle\", \"rb\")\n",
    "\n",
    "reseñas = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Luego, procederemos a dejar el corpus como una lista de sentencias </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "reseña_sent_token = []\n",
    "\n",
    "for i in range(len((reseñas))):\n",
    "    reseña_sent_token.append(sent_tokenize(reseñas[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I have bought several of the Vitality canned dog food products and have found them all to be of good quality.',\n",
       " 'The product looks more like a stew than a processed meat and it smells better.',\n",
       " 'My Labrador is finicky and she appreciates this product better than  most.']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reseña_sent_token is a list of list that contain a tokenize sentences\n",
    "reseña_sent_token[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2<li style =\"margin: 12px 0px;\">\n",
    "<p style=\"font-size:16px\"> Convierta el corpus , de modo que solo existan minúsculas (<code>lowercase</code>). </p></li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus = []\n",
    "\n",
    "for i in range(len(reseña_sent_token)):\n",
    "    for j in range(len(reseña_sent_token[i])):\n",
    "        corpus.append(reseña_sent_token[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2839271"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus) #corpus is a list of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save corpus for sentimental analisys \n",
    "#Using Pickle for save de state of corpus\n",
    "import pickle\n",
    "\n",
    "pickle_out = open(\"corpus_sent_tokenize.pickle\", \"wb\")\n",
    "pickle.dump(corpus, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correr desde acá para Sentymental Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle_in = open(\"corpus_sent_tokenize.pickle\", \"rb\")\n",
    "\n",
    "corpus = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(corpus)):\n",
    "    corpus[i] = corpus[i].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2839271"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Corpus is a list with all words of our sentences, not a list of list. \n",
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus_word_tokenize = []\n",
    "\n",
    "for i in range(len(corpus)):\n",
    "    corpus_word_tokenize.append(word_tokenize(corpus[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<li style =\"margin: 12px 0px;\">\n",
    "<p style=\"font-size:16px\" > Usando la lista de stopwords ortorgada por nltk, elimine aquellas palabras que sean clasificadas como stopwords, es decir, aquellas palabras que poseen poco contexto léxico y no otorgan información relevante. </p></li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words =set(stopwords.words(\"english\"))\n",
    "stop_words.update(['.', '``', \"''\", '-', '--','...', ',', '\"', \"'\", '?', '!', ':', ';', '(', ')', '[', ']', '{', '}']) \n",
    "\n",
    "corpus_filtered = []\n",
    "\n",
    "for i in corpus_word_tokenize:\n",
    "    for j in i:\n",
    "        if j not in stop_words:\n",
    "            corpus_filtered.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23702227"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "corpus = open(\"corpus_word_tokenize.pickle\", \"wb\")\n",
    "pickle.dump(corpus_filtered, corpus)\n",
    "corpus.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desde acá comenzamos con el corpus ya tokenizado a nivel de word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle_in = open(\"corpus_word_tokenize.pickle\", \"rb\")\n",
    "\n",
    "corpus = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\n",
    "<li style =\"margin: 12px 0px;\">\n",
    "<p style=\"font-size:16px\" > Elimine las palabras que aparezcan en el corpus con una frecuencia inferior a un umbral definido (ejemplo : inferior a 3) ( para ello, es recomendable determinar previo la frecuencia de cada término usando un diccionario). </p></li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#corpus_filterbyfreq contain the words with frequency > 5 \n",
    "corpus_filterbyfreq = []\n",
    "\n",
    "#diccionario de palabras\n",
    "diccionario = {}\n",
    "\n",
    "for i in set(corpus):\n",
    "    diccionario[i] = 0\n",
    "\n",
    "for i in corpus:\n",
    "    diccionario[i]+= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in corpus:\n",
    "    if(diccionario[i]>5):\n",
    "        corpus_filterbyfreq.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\n",
    "<li style =\"margin: 12px 0px;\">\n",
    "<p style=\"font-size:16px\" > Usando nltk, determine los Top-30 collocations mas relevantes del corpus, usando Bigramas .Implemente la función <code>BigramAssocMeasures()</code> y <code>BigramCollocationFinder.from_words()</code>. Recuerde que para este punto el corpus debe estar tokenizado. (mirar documentación). </p></li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing Top 30 collocations: \n",
      "[('tea', 'tea'), ('coffee', 'coffee'), ('food', 'food'), ('chips', 'chips'), ('chocolate', 'chocolate'), ('popcorn', 'popcorn'), ('dog', 'dog'), ('peanut', 'butter'), ('>', '>'), ('cat', 'cat'), ('cookies', 'cookies'), ('water', 'water'), ('salt', 'salt'), ('green', 'tea'), ('%', '%'), ('hair', 'hair'), ('coconut', 'coconut'), ('treats', 'treats'), ('cup', 'coffee'), ('cat', 'food'), ('oil', 'oil'), ('bars', 'bars'), ('sauce', 'sauce'), ('rice', 'rice'), ('gluten', 'free'), ('dog', 'food'), ('$', '$'), ('bread', 'bread'), ('cereal', 'cereal'), ('jerky', 'jerky')]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.collocations import * \n",
    "\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "finder = BigramCollocationFinder.from_words(corpus_filterbyfreq, 30)\n",
    "finder.apply_freq_filter(5)\n",
    "print('Printing Top 30 collocations: ')\n",
    "print(finder.nbest(bigram_measures.likelihood_ratio, 30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6\n",
    "<li style =\"margin: 12px 0px;\">\n",
    "<p style=\"font-size:16px\" > Usando la libreria incorporada en nltk, implemente Stanford POS tagger para categorizar y obtener los tags de cada token del corpus usando Part-Of-Speech Tagger (POSTagger). </p></li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bought',\n",
       " 'several',\n",
       " 'vitality',\n",
       " 'canned',\n",
       " 'dog',\n",
       " 'food',\n",
       " 'products',\n",
       " 'found',\n",
       " 'good',\n",
       " 'quality']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus_filterbyfreq)\n",
    "corpus_filterbyfreq[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Found C:/Program Files/Java/jdk1.8.0_121/bin/: C:/Program Files/Java/jdk1.8.0_121/bin/java.exe]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "java_path=\"C:/Program Files/Java/jdk1.8.0_121/bin/java.exe\"\n",
    "os.environ['JAVAHOME'] = java_path\n",
    "\n",
    "nltk.internals.config_java(\"C:/Program Files/Java/jdk1.8.0_121/bin/\")\n",
    "jar = '../stanford-postagger-full-2016-10-31/stanford-postagger.jar'\n",
    "model = '../stanford-postagger-full-2016-10-31/models/english-left3words-distsim.tagger'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.tag import StanfordPOSTagger\n",
    "\n",
    "pos_tagger = StanfordPOSTagger(model, jar, encoding='utf8')\n",
    "\n",
    "tags = pos_tagger.tag(corpus_filterbyfreq[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bought', 'VBD'),\n",
       " ('several', 'JJ'),\n",
       " ('vitality', 'NN'),\n",
       " ('canned', 'VBD'),\n",
       " ('dog', 'NN'),\n",
       " ('food', 'NN'),\n",
       " ('products', 'NNS'),\n",
       " ('found', 'VBD'),\n",
       " ('good', 'JJ'),\n",
       " ('quality', 'NN'),\n",
       " ('product', 'NN'),\n",
       " ('looks', 'VBZ'),\n",
       " ('like', 'IN'),\n",
       " ('stew', 'NN'),\n",
       " ('processed', 'VBN'),\n",
       " ('meat', 'NN'),\n",
       " ('smells', 'VBZ'),\n",
       " ('better', 'JJR'),\n",
       " ('labrador', 'NN'),\n",
       " ('finicky', 'JJ'),\n",
       " ('appreciates', 'VBZ'),\n",
       " ('product', 'NN'),\n",
       " ('better', 'JJR'),\n",
       " ('product', 'NN'),\n",
       " ('arrived', 'VBD'),\n",
       " ('labeled', 'VBN'),\n",
       " ('jumbo', 'JJ'),\n",
       " ('salted', 'JJ'),\n",
       " ('peanuts', 'NNS'),\n",
       " ('peanuts', 'NNS'),\n",
       " ('actually', 'RB'),\n",
       " ('small', 'JJ'),\n",
       " ('sized', 'VBN'),\n",
       " ('unsalted', 'JJ'),\n",
       " ('sure', 'JJ'),\n",
       " ('error', 'NN'),\n",
       " ('vendor', 'NN'),\n",
       " ('intended', 'VBN'),\n",
       " ('represent', 'VBP'),\n",
       " ('product', 'NN'),\n",
       " ('jumbo', 'JJ'),\n",
       " ('confection', 'NN'),\n",
       " ('around', 'IN'),\n",
       " ('centuries', 'NNS'),\n",
       " ('light', 'JJ'),\n",
       " ('pillowy', 'JJ'),\n",
       " ('citrus', 'NN'),\n",
       " ('gelatin', 'NN'),\n",
       " ('nuts', 'NNS'),\n",
       " ('case', 'NN'),\n",
       " ('filberts', 'NNS'),\n",
       " ('cut', 'VBD'),\n",
       " ('tiny', 'JJ'),\n",
       " ('squares', 'NNS'),\n",
       " ('liberally', 'RB'),\n",
       " ('coated', 'JJ'),\n",
       " ('powdered', 'JJ'),\n",
       " ('sugar', 'NN'),\n",
       " ('tiny', 'JJ'),\n",
       " ('mouthful', 'JJ'),\n",
       " ('heaven', 'NN'),\n",
       " ('chewy', 'JJ'),\n",
       " ('flavorful', 'JJ'),\n",
       " ('highly', 'RB'),\n",
       " ('recommend', 'VB'),\n",
       " ('yummy', 'JJ'),\n",
       " ('treat', 'NN'),\n",
       " ('familiar', 'JJ'),\n",
       " ('story', 'NN'),\n",
       " ('c.s', 'NNS'),\n",
       " ('lewis', 'VBZ'),\n",
       " ('lion', 'NN'),\n",
       " ('witch', 'NN'),\n",
       " ('wardrobe', 'NN'),\n",
       " ('treat', 'NN'),\n",
       " ('edmund', 'NN'),\n",
       " ('selling', 'VBG'),\n",
       " ('brother', 'NN'),\n",
       " ('sisters', 'NNS'),\n",
       " ('witch', 'NN'),\n",
       " ('looking', 'VBG'),\n",
       " ('secret', 'JJ'),\n",
       " ('ingredient', 'NN'),\n",
       " ('robitussin', 'NN'),\n",
       " ('believe', 'VBP'),\n",
       " ('found', 'VBN'),\n",
       " ('got', 'VBD'),\n",
       " ('addition', 'NN'),\n",
       " ('root', 'NN'),\n",
       " ('beer', 'NN'),\n",
       " ('extract', 'NN'),\n",
       " ('ordered', 'VBD'),\n",
       " ('good', 'JJ'),\n",
       " ('made', 'VBN'),\n",
       " ('cherry', 'NN'),\n",
       " ('soda', 'NN'),\n",
       " ('flavor', 'NN'),\n",
       " ('medicinal', 'JJ'),\n",
       " ('great', 'JJ'),\n",
       " ('taffy', 'NN')]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7\n",
    "<li style =\"margin: 12px 0px;\">\n",
    "<p style=\"font-size:16px\" > Usando la libreria incorporada en nltk, implemente Named Entity Recognition (NER) con Stanford NER Tagger. Analice y describa sus resultados. </p></li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('bought', 'O'), ('several', 'O'), ('vitality', 'O'), ('canned', 'O'), ('dog', 'O'), ('food', 'O'), ('products', 'O'), ('found', 'O'), ('good', 'O'), ('quality', 'O'), ('product', 'O'), ('looks', 'O'), ('like', 'O'), ('stew', 'O'), ('processed', 'O'), ('meat', 'O'), ('smells', 'O'), ('better', 'O'), ('labrador', 'O'), ('finicky', 'O'), ('appreciates', 'O'), ('product', 'O'), ('better', 'O'), ('product', 'O'), ('arrived', 'O'), ('labeled', 'O'), ('jumbo', 'O'), ('salted', 'O'), ('peanuts', 'O'), ('peanuts', 'O'), ('actually', 'O'), ('small', 'O'), ('sized', 'O'), ('unsalted', 'O'), ('sure', 'O'), ('error', 'O'), ('vendor', 'O'), ('intended', 'O'), ('represent', 'O'), ('product', 'O'), ('jumbo', 'O'), ('confection', 'O'), ('around', 'O'), ('centuries', 'O'), ('light', 'O'), ('pillowy', 'O'), ('citrus', 'O'), ('gelatin', 'O'), ('nuts', 'O'), ('case', 'O'), ('filberts', 'O'), ('cut', 'O'), ('tiny', 'O'), ('squares', 'O'), ('liberally', 'O'), ('coated', 'O'), ('powdered', 'O'), ('sugar', 'O'), ('tiny', 'O'), ('mouthful', 'O'), ('heaven', 'O'), ('chewy', 'O'), ('flavorful', 'O'), ('highly', 'O'), ('recommend', 'O'), ('yummy', 'O'), ('treat', 'O'), ('familiar', 'O'), ('story', 'O'), ('c.s', 'O'), ('lewis', 'O'), ('lion', 'O'), ('witch', 'O'), ('wardrobe', 'O'), ('treat', 'O'), ('edmund', 'O'), ('selling', 'O'), ('brother', 'O'), ('sisters', 'O'), ('witch', 'O'), ('looking', 'O'), ('secret', 'O'), ('ingredient', 'O'), ('robitussin', 'O'), ('believe', 'O'), ('found', 'O'), ('got', 'O'), ('addition', 'O'), ('root', 'O'), ('beer', 'O'), ('extract', 'O'), ('ordered', 'O'), ('good', 'O'), ('made', 'O'), ('cherry', 'O'), ('soda', 'O'), ('flavor', 'O'), ('medicinal', 'O'), ('great', 'O'), ('taffy', 'O')]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tag import StanfordNERTagger\n",
    "\n",
    "st = StanfordNERTagger('../stanford-ner-2016-10-31/classifiers/english.all.3class.distsim.crf.ser.gz', '../stanford-ner-2016-10-31/stanford-ner.jar', encoding='utf-8')\n",
    "\n",
    "print(st.tag(corpus_filterbyfreq[0:100]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8\n",
    "<li style =\"margin: 12px 0px;\">\n",
    "<p style=\"font-size:16px\" > <strong> Sentiment Analysis </strong>: Implemente usando la libreria <i>Vader</i> incorporada en nltk para analizar la polaridad del corpus ,determinar cada documento (para ello es necesario re-estructurar el corpus como un array de documentos, o sentencias):</p>\n",
    "<ol>\n",
    "<li> Tokenizar el corpus a nivel de sentencia (recuerde incorporar el preprocesamiento previo).</li>\n",
    "<li> Para cada sentencias (reseña) , implemente Vader para determinar la polaridad.</li>\n",
    "</ol>\n",
    "</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have bought several of the Vitality canned dog food products and have found them all to be of good quality.\n",
      "compound: 0.6369, neg: 0.0, neu: 0.776, pos: 0.224, \n",
      "The product looks more like a stew than a processed meat and it smells better.\n",
      "compound: 0.6901, neg: 0.0, neu: 0.659, pos: 0.341, \n",
      "My Labrador is finicky and she appreciates this product better than  most.\n",
      "compound: 0.7351, neg: 0.0, neu: 0.617, pos: 0.383, \n",
      "Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted.\n",
      "compound: 0.0, neg: 0.0, neu: 1.0, pos: 0.0, \n",
      "Not sure if this was an error or if the vendor intended to represent the product as \"Jumbo\".\n",
      "compound: -0.1027, neg: 0.129, neu: 0.762, pos: 0.11, \n",
      "This is a confection that has been around a few centuries.\n",
      "compound: 0.0, neg: 0.0, neu: 1.0, pos: 0.0, \n",
      "It is a light, pillowy citrus gelatin with nuts - in this case Filberts.\n",
      "compound: -0.3182, neg: 0.173, neu: 0.827, pos: 0.0, \n",
      "And it is cut into tiny squares and then liberally coated with powdered sugar.\n",
      "compound: -0.2732, neg: 0.139, neu: 0.861, pos: 0.0, \n",
      "And it is a tiny mouthful of heaven.\n",
      "compound: 0.5106, neg: 0.0, neu: 0.645, pos: 0.355, \n",
      "Not too chewy, and very flavorful.\n",
      "compound: 0.0, neg: 0.0, neu: 1.0, pos: 0.0, \n",
      "I highly recommend this yummy treat.\n",
      "compound: 0.8696, neg: 0.0, neu: 0.169, pos: 0.831, \n",
      "If you are familiar with the story of C.S.\n",
      "compound: 0.0, neg: 0.0, neu: 1.0, pos: 0.0, \n",
      "Lewis' \"The Lion, The Witch, and The Wardrobe\" - this is the treat that seduces Edmund into selling out his Brother and Sisters to the Witch.\n",
      "compound: -0.3182, neg: 0.168, neu: 0.741, pos: 0.091, \n",
      "If you are looking for the secret ingredient in Robitussin I believe I have found it.\n",
      "compound: 0.0, neg: 0.0, neu: 1.0, pos: 0.0, \n",
      "I got this in addition to the Root Beer Extract I ordered (which was good) and made some cherry soda.\n",
      "compound: 0.0, neg: 0.0, neu: 1.0, pos: 0.0, \n",
      "The flavor is very medicinal.\n",
      "compound: 0.0, neg: 0.0, neu: 1.0, pos: 0.0, \n",
      "Great taffy at a great price.\n",
      "compound: 0.8481, neg: 0.0, neu: 0.268, pos: 0.732, \n",
      "There was a wide assortment of yummy taffy.\n",
      "compound: 0.5267, neg: 0.0, neu: 0.638, pos: 0.362, \n",
      "Delivery was very quick.\n",
      "compound: 0.0, neg: 0.0, neu: 1.0, pos: 0.0, \n",
      "If your a taffy lover, this is a deal.\n",
      "compound: 0.5859, neg: 0.0, neu: 0.612, pos: 0.388, \n",
      "I got a wild hair for taffy and ordered this five pound bag.\n",
      "compound: 0.0, neg: 0.0, neu: 1.0, pos: 0.0, \n",
      "The taffy was all very enjoyable with many flavors: watermelon, root beer, melon, peppermint, grape, etc.\n",
      "compound: 0.4927, neg: 0.0, neu: 0.824, pos: 0.176, \n",
      "My only complaint is there was a bit too much red/black licorice-flavored pieces (just not my particular favorites).\n",
      "compound: -0.296, neg: 0.121, neu: 0.879, pos: 0.0, \n",
      "Between me, my kids, and my husband, this lasted only two weeks!\n",
      "compound: 0.0, neg: 0.0, neu: 1.0, pos: 0.0, \n",
      "I would recommend this brand of taffy -- it was a delightful treat.\n",
      "compound: 0.8402, neg: 0.0, neu: 0.471, pos: 0.529, \n",
      "This saltwater taffy had great flavors and was very soft and chewy.\n",
      "compound: 0.6249, neg: 0.0, neu: 0.728, pos: 0.272, \n",
      "Each candy was individually wrapped well.\n",
      "compound: 0.2732, neg: 0.0, neu: 0.704, pos: 0.296, \n",
      "None of the candies were stuck together, which did happen in the expensive version, Fralinger's.\n",
      "compound: -0.25, neg: 0.125, neu: 0.875, pos: 0.0, \n",
      "Would highly recommend this candy!\n",
      "compound: 0.474, neg: 0.0, neu: 0.565, pos: 0.435, \n",
      "I served it at a beach-themed party and everyone loved it!\n",
      "compound: 0.784, neg: 0.0, neu: 0.504, pos: 0.496, \n",
      "This taffy is so good.\n",
      "compound: 0.5777, neg: 0.0, neu: 0.517, pos: 0.483, \n",
      "It is very soft and chewy.\n",
      "compound: 0.0, neg: 0.0, neu: 1.0, pos: 0.0, \n",
      "The flavors are amazing.\n",
      "compound: 0.5859, neg: 0.0, neu: 0.441, pos: 0.559, \n",
      "I would definitely recommend you buying it.\n",
      "compound: 0.6369, neg: 0.0, neu: 0.435, pos: 0.565, \n",
      "Very satisfying!\n",
      "compound: 0.5551, neg: 0.0, neu: 0.218, pos: 0.782, \n",
      "!\n",
      "compound: 0.0, neg: 0.0, neu: 0.0, pos: 0.0, \n",
      "Right now I'm mostly just sprouting this so my cats can eat the grass.\n",
      "compound: 0.0, neg: 0.0, neu: 1.0, pos: 0.0, \n",
      "They love it.\n",
      "compound: 0.6369, neg: 0.0, neu: 0.323, pos: 0.677, \n",
      "I rotate it around with Wheatgrass and Rye too\n",
      "compound: 0.0, neg: 0.0, neu: 1.0, pos: 0.0, \n",
      "This is a very healthy dog food.\n",
      "compound: 0.4576, neg: 0.0, neu: 0.626, pos: 0.374, \n",
      "Good for their digestion.\n",
      "compound: 0.4404, neg: 0.0, neu: 0.508, pos: 0.492, \n",
      "Also good for small puppies.\n",
      "compound: 0.4404, neg: 0.0, neu: 0.58, pos: 0.42, \n",
      "My dog eats her required amount at every feeding.\n",
      "compound: 0.0, neg: 0.0, neu: 1.0, pos: 0.0, \n",
      "I don't know if it's the cactus or the tequila or just the unique combination of ingredients, but the flavour of this hot sauce makes it one of a kind!\n",
      "compound: 0.7088, neg: 0.0, neu: 0.847, pos: 0.153, \n",
      "We picked up a bottle once on a trip we were on and brought it back home with us and were totally blown away!\n",
      "compound: 0.0, neg: 0.0, neu: 1.0, pos: 0.0, \n",
      "When we realized that we simply couldn't find it anywhere in our city we were bummed.Now, because of the magic of the internet, we have a case of the sauce and are ecstatic because of it.If you love hot sauce..I mean really love hot sauce, but don't want a sauce that tastelessly burns your throat, grab a bottle of Tequila Picante Gourmet de Inclan.\n",
      "compound: 0.7199, neg: 0.02, neu: 0.868, pos: 0.112, \n",
      "Just realize that once you taste it, you will never want to use any other sauce.Thank you for the personal, incredible service!\n",
      "compound: -0.1316, neg: 0.067, neu: 0.933, pos: 0.0, \n",
      "One of my boys needed to lose some weight and the other didn't.\n",
      "compound: -0.4019, neg: 0.184, neu: 0.816, pos: 0.0, \n",
      "I put this food on the floor for the chubby guy, and the protein-rich, no by-product food up higher where only my skinny boy can jump.\n",
      "compound: -0.296, neg: 0.084, neu: 0.916, pos: 0.0, \n",
      "The higher food sits going stale.\n",
      "compound: 0.0, neg: 0.0, neu: 1.0, pos: 0.0, \n",
      "They both really go for this food.\n",
      "compound: 0.0, neg: 0.0, neu: 1.0, pos: 0.0, \n",
      "And my chubby boy has been losing about an ounce a week.\n",
      "compound: -0.3818, neg: 0.206, neu: 0.794, pos: 0.0, \n",
      "My cats have been happily eating Felidae Platinum for more than two years.\n",
      "compound: 0.5574, neg: 0.0, neu: 0.769, pos: 0.231, \n",
      "I just got a new bag and the shape of the food is different.\n",
      "compound: 0.0, neg: 0.0, neu: 1.0, pos: 0.0, \n",
      "They tried the new food when I first put it in their bowls and now the bowls sit full and the kitties will not touch the food.\n",
      "compound: 0.0, neg: 0.0, neu: 1.0, pos: 0.0, \n",
      "I've noticed similar reviews related to formula changes in the past.\n",
      "compound: 0.0, neg: 0.0, neu: 1.0, pos: 0.0, \n",
      "Unfortunately, I now need to find a new food that my cats will eat.\n",
      "compound: -0.34, neg: 0.179, neu: 0.821, pos: 0.0, \n",
      "good flavor!\n",
      "compound: 0.4926, neg: 0.0, neu: 0.239, pos: 0.761, \n",
      "these came securely packed... they were fresh and delicious!\n",
      "compound: 0.8268, neg: 0.0, neu: 0.408, pos: 0.592, \n",
      "i love these Twizzlers!\n",
      "compound: 0.6696, neg: 0.0, neu: 0.308, pos: 0.692, \n",
      "The Strawberry Twizzlers are my guilty pleasure - yummy.\n",
      "compound: 0.6486, neg: 0.188, neu: 0.336, pos: 0.477, \n",
      "Six pounds will be around for a while with my son and I.\n",
      "compound: 0.0, neg: 0.0, neu: 1.0, pos: 0.0, \n",
      "My daughter loves twizzlers and this shipment of six pounds really hit the spot.\n",
      "compound: 0.5719, neg: 0.0, neu: 0.778, pos: 0.222, \n",
      "It's exactly what you would expect...six packages of strawberry twizzlers.\n",
      "compound: 0.0, neg: 0.0, neu: 1.0, pos: 0.0, \n",
      "I love eating them and they are good for watching TV and looking at movies!\n",
      "compound: 0.8122, neg: 0.0, neu: 0.619, pos: 0.381, \n",
      "It is not too sweet.\n",
      "compound: -0.357, neg: 0.383, neu: 0.617, pos: 0.0, \n",
      "I like to transfer them to a zip lock baggie so they stay fresh so I can take my time eating them.\n",
      "compound: 0.6204, neg: 0.0, neu: 0.77, pos: 0.23, \n",
      "I am very satisfied with my Twizzler purchase.\n",
      "compound: 0.4754, neg: 0.0, neu: 0.66, pos: 0.34, \n",
      "I shared these with others and we have all enjoyed them.\n",
      "compound: 0.6908, neg: 0.0, neu: 0.584, pos: 0.416, \n",
      "I will definitely be ordering more.\n",
      "compound: 0.4019, neg: 0.0, neu: 0.597, pos: 0.403, \n",
      "Twizzlers, Strawberry my childhood favorite candy, made in Lancaster Pennsylvania by Y & S Candies, Inc. one of the oldest confectionery Firms in the United States, now a Subsidiary of the Hershey Company, the Company was established in 1845 as Young and Smylie, they also make Apple Licorice Twists, Green Color and Blue Raspberry Licorice Twists, I like them allI keep it in a dry cool place because is not recommended it to put it in the fridge.\n",
      "compound: 0.8405, neg: 0.02, neu: 0.846, pos: 0.134, \n",
      "According to the Guinness Book of Records, the longest Licorice Twist ever made measured 1.200 Feet (370 M) and weighted 100 Pounds (45 Kg) and was made by Y & S Candies, Inc.\n",
      "compound: 0.0, neg: 0.0, neu: 1.0, pos: 0.0, \n",
      "This Record-Breaking Twist became a Guinness World Record on July 19, 1998.\n",
      "compound: 0.0, neg: 0.0, neu: 1.0, pos: 0.0, \n",
      "This Product is Kosher!\n",
      "compound: 0.0, neg: 0.0, neu: 1.0, pos: 0.0, \n",
      "Thank You\n",
      "compound: 0.3612, neg: 0.0, neu: 0.286, pos: 0.714, \n",
      "Candy was delivered very fast and was purchased at a reasonable price.\n",
      "compound: 0.0, neg: 0.0, neu: 1.0, pos: 0.0, \n",
      "I was home bound and unable to get to a store so this was perfect for me.\n",
      "compound: 0.6077, neg: 0.0, neu: 0.779, pos: 0.221, \n",
      "My husband is a Twizzlers addict.\n",
      "compound: 0.0, neg: 0.0, neu: 1.0, pos: 0.0, \n",
      "We've bought these many times from Amazon because we're government employees living overseas and can't get them in the country we are assigned to.\n",
      "compound: 0.1779, neg: 0.0, neu: 0.931, pos: 0.069, \n",
      "They've always been fresh and tasty, packed well and arrive in a timely manner.\n",
      "compound: 0.5267, neg: 0.0, neu: 0.714, pos: 0.286, \n",
      "I bought these for my husband who is currently overseas.\n",
      "compound: 0.0, neg: 0.0, neu: 1.0, pos: 0.0, \n",
      "He loves these, and apparently his staff likes them also.There are generous amounts of Twizzlers in each 16-ounce bag, and this was well worth the price.\n",
      "compound: 0.9153, neg: 0.0, neu: 0.603, pos: 0.397, \n",
      "Twizzlers, Strawberry, 16-Ounce Bags (Pack of 6)\n",
      "compound: 0.0, neg: 0.0, neu: 1.0, pos: 0.0, \n",
      "I can remember buying this candy as a kid and the quality hasn't dropped in all these years.\n",
      "compound: 0.0, neg: 0.0, neu: 1.0, pos: 0.0, \n",
      "Still a superb product you won't be disappointed with.\n",
      "compound: 0.7687, neg: 0.0, neu: 0.474, pos: 0.526, \n",
      "I love this candy.\n",
      "compound: 0.6369, neg: 0.0, neu: 0.323, pos: 0.677, \n",
      "After weight watchers I had to cut back but still have a craving for it.\n",
      "compound: -0.1406, neg: 0.114, neu: 0.886, pos: 0.0, \n",
      "I have lived out of the US for over 7 yrs now, and I so miss my Twizzlers!!\n",
      "compound: -0.402, neg: 0.162, neu: 0.838, pos: 0.0, \n",
      "When I go back to visit or someone visits me, I always stock up.\n",
      "compound: 0.0, neg: 0.0, neu: 1.0, pos: 0.0, \n",
      "All I can say is YUM!Sell these in Mexico and you will have a faithful buyer, more often than I'm able to buy them right now.\n",
      "compound: 0.4926, neg: 0.0, neu: 0.878, pos: 0.122, \n",
      "Product received is as advertised.Twizzlers, Strawberry, 16-Ounce Bags (Pack of 6)\n",
      "compound: 0.0, neg: 0.0, neu: 1.0, pos: 0.0, \n",
      "The candy is just red , No flavor .\n",
      "compound: -0.296, neg: 0.268, neu: 0.732, pos: 0.0, \n",
      "Just  plan and chewy .\n",
      "compound: 0.0, neg: 0.0, neu: 1.0, pos: 0.0, \n",
      "I would never buy them again\n",
      "compound: 0.0, neg: 0.0, neu: 1.0, pos: 0.0, \n",
      "I was so glad Amazon carried these batteries.\n",
      "compound: 0.6453, neg: 0.0, neu: 0.487, pos: 0.513, \n",
      "I have a hard time finding them elsewhere because they are such a unique size.\n",
      "compound: -0.1027, neg: 0.113, neu: 0.887, pos: 0.0, \n",
      "I need them for my garage door opener.Great deal for the price.\n",
      "compound: 0.0, neg: 0.0, neu: 1.0, pos: 0.0, \n",
      "I got this for my Mum who is not diabetic but needs to watch her sugar intake, and my father who simply chooses to limit unnecessary sugar intake - she's the one with the sweet tooth - they both LOVED these toffees, you would never guess that they're sugar-free and it's so great that you can eat them pretty much guilt free!\n",
      "compound: 0.9821, neg: 0.032, neu: 0.642, pos: 0.325, \n",
      "i was so impressed that i've ordered some for myself (w dark chocolate) to take to the office so i'll eat them instead of snacking on sugary sweets.These are just EXCELLENT!\n",
      "compound: 0.8449, neg: 0.0, neu: 0.775, pos: 0.225, \n",
      "I don't know if it's the cactus or the tequila or just the unique combination of ingredients, but the flavour of this hot sauce makes it one of a kind!\n",
      "compound: 0.7088, neg: 0.0, neu: 0.847, pos: 0.153, \n"
     ]
    }
   ],
   "source": [
    "sid = SentimentIntensityAnalyzer()\n",
    "for sentence in corpus[0:100]:\n",
    "    print(sentence)\n",
    "    ss = sid.polarity_scores(sentence)\n",
    "    for k in sorted(ss):\n",
    "        print('{0}: {1}, '.format(k, ss[k]), end='')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Notas</h2>\n",
    "<ul>\n",
    "<li style =\"margin: 12px 0px; font-size: 16px\" >\n",
    "Para varias etapas del preprocesamiento, usará diferentes librerias disponibles en Python. Se recomienda usar el instalador de paquetes <i>pip</i> ( link: https://pypi.python.org/pypi/pip ) .\n",
    "</li>\n",
    "<li style =\"margin: 12px 0px; font-size: 16px\" >\n",
    "Algunos de estos pasos del preprocesamiento pueden demorar en compilar (en algunos casos sobre 45 min, dependiendo de la máquina), por lo que es recomendable ir guardando el estado del corpus su posterior uso. Para estos casos se recomienda usar la libreria <code> pickle </code> en python (link: https://docs.python.org/2/library/pickle.html ) \n",
    "</li>\n",
    "</ul>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Documentación y Ejemplos</h2>\n",
    "<ul>\n",
    "<li style =\"margin: 12px 0px;\" >\n",
    "Beautiful Soup :\n",
    "https://www.crummy.com/software/BeautifulSoup/\n",
    "</li>\n",
    "<li style =\"margin: 12px 0px;\" >\n",
    "Bigrams and Collocations:\n",
    "http://www.nltk.org/howto/collocations.html\n",
    "</li>\n",
    "<li style =\"margin: 12px 0px;\" >\n",
    "Stanford PoS Tagger :\n",
    "http://www.nltk.org/api/nltk.tag.html#module-nltk.tag.stanford\n",
    "</li>\n",
    "<li>\n",
    "Stanford 'Tagger' Link Download : https://nlp.stanford.edu/software/tagger.shtml#Download\n",
    "</li>\n",
    "<li style =\"margin: 12px 0px;\" >\n",
    "Stanford Ner Tagger:\n",
    "https://pythonprogramming.net/named-entity-recognition-stanford-ner-tagger/\n",
    "</li>\n",
    "<li style =\"margin: 12px 0px;\" >\n",
    "Sentiment Analysis with Vader: \n",
    "http://www.nltk.org/howto/sentiment.html\n",
    "</li>\n",
    "\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Instrucciones</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol >\n",
    "<li style =\"margin: 12px 0px;\" >\n",
    "<p style=\"font-size:16px\" > El informe debe entregarse en un archivo jupyter notebook (diferente a este) con el código  implementado y los análisis correspondientes. El informe debe subirse en la plataforma oficial de moodle en formato comprimido (.zip) con el nombre <i>tarea1_rol.zip</i></p> </li>\n",
    "\n",
    "<li style =\"margin: 12px 0px;\" >\n",
    "<p style=\"font-size:16px\" > Todas las consultas serán atendidas por el canal de consultas de moodle. </i></p> </li>\n",
    "\n",
    "<li style =\"margin: 12px 0px;\" >\n",
    "<p style=\"font-size:16px\" > La fecha de entrega es el dia <strong>10 de Abril</strong> . Pasada esa fecha se descontaran 20 puntos por dia. </p> </li>\n",
    "\n",
    "\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
